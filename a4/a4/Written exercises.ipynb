{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 g)\n",
    "\n",
    "It generates a mask that is ones after the input sequence ends, and those values will be set to -inf in the e_t so the pad element will never be used to count attention scores as that would make no sense since they are not a part of the actual sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 j)\n",
    "\n",
    "Attentions:\n",
    "\n",
    "* Dot attention allows for fast compute, but at the cost of flexibility\n",
    "* Multiplicative has an adjustable weight matrix, but still only one that has to take care weighing both the input states and current state with just matrix\n",
    "* Additive attention allows for differing weights depending on the current state and the input sentence => likely more accurate but requiring more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 a)\n",
    "\n",
    "1. Can't come up with the phrase 'one of my favorites', maybe this is due to the model predicting that here is a favorite first and then 'of my favorites'\n",
    "2. The phrase most read author in US is formed differently in Spanish and the model does not recognize this, but rather gives a more direct translation to the phrase I would guess. Not a Spanish expert myself either.\n",
    "3. Out of vocabulary word, needs to be added.\n",
    "4. Again trying to directly translate some more complex phrase.\n",
    "5. Attention on the wrong word here perhaps causing it to be the women's room instead of the teacher's room?\n",
    "6. Model limited, different units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('./outputs/test_outputs.txt').readlines()\n",
    "sp = open('./en_es_data/test.es').readlines()\n",
    "en = open('./en_es_data/test.en').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  A travs de un proceso de perfeccionamiento, ensayo y error y una gran cantidad de pruebas con usuarios, trat de reducir este complicado concepto de ciudades bajo estatuto a sus ideas ms esenciales.\n",
      " Reference Translation:  Through a process of refinement,  trial and error, a lot of user testing,  I tried to boil this complicated concept of charter city  down to the bare essentials.\n",
      " NMT Translation:  Through a process of <unk> trial and error and a lot of testing with users, I tried to reduce this complicated concept of cities under <unk> to their most essential.\n",
      " \n",
      "\n",
      "Source Sentence:  Me pregunto si deberamos dar el salto y tratar de inventar mejores maneras de hacer todas estas cosas.\n",
      " Reference Translation:  And so I wonder if we should just take a leap  and try to invent better ways to do all these things.\n",
      " NMT Translation:  I wonder if we should take the leap and try to invent better ways to do all of these things.\n",
      " \n",
      "\n",
      "Source Sentence:  Este es el cable.\n",
      " Reference Translation:  This is the cord.\n",
      " NMT Translation:  This is the wire.\n",
      " \n",
      "\n",
      "Source Sentence:  \"Ash, alguna vez estuviste en el Castro?\"\n",
      " Reference Translation:  \"Ash, have you ever been to the Castro?\"\n",
      " NMT Translation:  <unk> once you were in the <unk>\n",
      " \n",
      "\n",
      "Source Sentence:  Surgi en la Universidad de Washington, en Seattle.\n",
      " Reference Translation:  It came out of the University of Washington in Seattle.\n",
      " NMT Translation:  <unk> at the University of Washington, in Seattle.\n",
      " \n",
      "\n",
      "Source Sentence:  \"Estoy ayudando al pueblo norcoreano\".\n",
      " Reference Translation:  \"I'm helping the North Korean people.\"\n",
      " NMT Translation:  \"I'm helping the village <unk>\n",
      " \n",
      "\n",
      "Source Sentence:  No estoy realmente seguro de la respuesta.\n",
      " Reference Translation:  I'm not really sure about the answer.\n",
      " NMT Translation:  I'm not really sure about the answer.\n",
      " \n",
      "\n",
      "Source Sentence:  El juego aumenta la creatividad y la resiliencia y tiene que ver con la generacin de diversidad... diversidad de interacciones, diversidad de comportamientos, diversidad de conexiones.\n",
      " Reference Translation:  Play increases creativity  and resilience,  and it's all about the generation of diversity --  diversity of interactions,  diversity of behaviors,  diversity of connections.\n",
      " NMT Translation:  Play increases creativity and resilience and it has to do with the generation of <unk> diversity of interactions, diversity of connecting connections.\n",
      " \n",
      "\n",
      "Source Sentence:  La privacidad no se discute.\n",
      " Reference Translation:  Privacy is not up for discussion.\n",
      " NMT Translation:  <unk> <unk>\n",
      " \n",
      "\n",
      "Source Sentence:  En el futuro, la mayora de los crmenes ocurrirn en lnea.\n",
      " Reference Translation:  In the future, the majority of crime  will be happening online.\n",
      " NMT Translation:  In the future, most <unk> crimes online.\n",
      " \n",
      "\n",
      "Source Sentence:  Se ve el Coliseo en el medio y el ro Tber.\n",
      " Reference Translation:  You see the Colosseum in the middle,  the river Tiber.\n",
      " NMT Translation:  You see the <unk> in the middle and the <unk> River.\n",
      " \n",
      "\n",
      "Source Sentence:  As que en conclusin, creo que para m, lo principal es que todas las cosas increbles realmente no provienen de Google.\n",
      " Reference Translation:  So I think, in conclusion,  for me, the main thing  is that all the amazing stuff here does not really come from Google.\n",
      " NMT Translation:  So in conclusion, I think for me, the main thing is that all the amazing things didn't come from Google.\n",
      " \n",
      "\n",
      "Source Sentence:  Pero antes de mostrarles lo que hay dentro, voy a hacer una confesin pblica, y es que, vivo obsesionada con los trajes.\n",
      " Reference Translation:  But before I show you what I've got inside,  I'm going to make a very public confession,  and that is,  I'm outfit-obsessed.\n",
      " NMT Translation:  But before I show you what there is -- I'm going to make a confession public and is that I live obsessed with <unk>\n",
      " \n",
      "\n",
      "Source Sentence:  Pero luego me gustara descubrir algo nuevo y diferente, y me gustara adentrarme en eso.\n",
      " Reference Translation:  But then I would discover something new and totally different,  and I would dive into that.\n",
      " NMT Translation:  But then I'd like to discover something new and different, and I'd like to go into that.\n",
      " \n",
      "\n",
      "Source Sentence:  Mi exterior finalmente concordaba con mi verdad interior, con mi yo interior.\n",
      " Reference Translation:  My outside self finally matched my inner truth,  my inner self.\n",
      " NMT Translation:  My outside finally <unk> my inner truth, with my inner self.\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "randoms = np.random.randint(0, len(out) - 1, 15)\n",
    "for i in randoms:\n",
    "    print('Source Sentence: ', sp[i], 'Reference Translation: ', en[i], 'NMT Translation: ', out[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the mistakes the system makes are due to out of vocabulary words. FOr the most part it does quite well, sometimes the verbs are in wrong form and it does not catch the meaning of some phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one translation means that different ways of translating the same sentence are not accepted even though they should as there isn't only one way of translating a sentence.\n",
    "\n",
    "Bleu does not capture the way humans understand languages and depending on the number of translations the results can vary a lot. It still is quite efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
